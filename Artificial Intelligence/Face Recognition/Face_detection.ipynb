{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Reading the image : \n",
    "The below listed code would read into the image passed as an argument to the program and convert it to grayscale. Also we would initialize the HaaR cascade model for pedestrian detect by using the HaaR cascade xml file as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagePath = sys.argv[1]\n",
    "cascPath = \"haarcascade_pedestrian.xml\"\n",
    "\n",
    "# cascPath = \"pedestrian_another.xml\"\n",
    "# cascPath = \"haarcascade_fullbody.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedsCascade =  cv2.CascadeClassifier(cascPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "image = cv2.imread('peds1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Detecting people in image : Using the HaaR cascade model initialized in last step, we run an detection on the input image and out the number of objects detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect pedestrian in pic\n",
    "\n",
    "peds = pedsCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=9,\n",
    "        minSize=(30, 30)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 pedestrian!\n"
     ]
    }
   ],
   "source": [
    "print(\"Found {0} pedestrian!\".format(len(peds)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Creating bounding box : Finally we shall create a bounding box around the objects detected in previous steps and write a new output image by the name of peds_saved.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a rectangle around the peds\n",
    "for (x, y, w, h) in peds:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image written to file-system :  True\n"
     ]
    }
   ],
   "source": [
    "# cv2.imshow(\"Faces found\", image)\n",
    "status = cv2.imwrite('peds_saved3.jpg', image)\n",
    "print (\"Image written to file-system : \",status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
