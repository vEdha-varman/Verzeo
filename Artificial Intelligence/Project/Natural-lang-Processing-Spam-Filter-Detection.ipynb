{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPAM DETECTION FILTER CLASSIFICATION OF EMAILS AS SPAM OR NOT (HAM)\n",
    "\n",
    "#ENVIRONMENT SET UP Install NLTK and the below libraries go to anaconda prompt from windows start conda install nltk from anaconda prompt or pip install nltk from python command prompt\n",
    "\n",
    "NOT RECOMMENDED-you can also install this in jupyter directly\n",
    "!conda install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#this step takes some time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition - Beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the purposes of this use case \n",
    "\n",
    "1. we will download our main dataset with spam and non spam messages from (https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)!\n",
    "\n",
    "2. Along with the above, we will need certain additional datasets that will help in processing the data from our main dataset from bullet 1. for this we use some of the internal dataset \"nltk\"  library has\n",
    "    - execute the command  \"nltk.download_shell()\" from jupyter\n",
    "        - This opens up an interactive shell with options like  d - for full download l.list, u for update, c for config, h Help \n",
    "          q for Quit\n",
    "        - Type l \"for list\" to list all the datasets in nltk\n",
    "        - type d \"for download\" \n",
    "        - the interactive shell asks you what dataset to download\n",
    "        - type \"stopwords\" to download the stopwords dataset\n",
    "        - the stopwords dataset has the most commonly used words in english like \"to\", \"and\",\"if\",\"the\" and many many more. \n",
    "           \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download_shell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " - Dataset corpus is downloaded from the (https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)! \n",
    "\n",
    " - This dataset is already collected and stored in the jupyter folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition - End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing - Beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The file we are using contains a collection of more than 5 thousand SMS phone messages.\n",
    "\n",
    "- use rstrip() plus a list comprehension to get a list of all the lines of text messages:\n",
    "- rstrip returns a copy of a string in which all characters have been stripped from the end of strip (default whitespace) characters)\n",
    "- list comprehension is a way to run the entire line of command as a list. watch the square brackets. output will be a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [line.rstrip() for line in open('smsspamcollection/SMSSpamCollection')]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
